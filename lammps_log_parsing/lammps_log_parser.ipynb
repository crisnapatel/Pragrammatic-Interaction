{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa5de391",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4eaee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "from typing import Dict, List, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29192cf",
   "metadata": {},
   "source": [
    "## LAMMPS Thermo Log Parser\n",
    "\n",
    "Parse thermodynamic data from LAMMPS simulation log files and extract specific properties into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24530d79",
   "metadata": {},
   "source": [
    "### Function: parse_thermo_log()\n",
    "\n",
    "**Purpose:** Extract thermo data from a LAMMPS log file\n",
    "\n",
    "**Parameters:**\n",
    "- `log_file` (str): Path to the LAMMPS log file\n",
    "- `properties` (list): List of property names to extract (case-sensitive, e.g., `['temp', 'press', 'pxx']`)\n",
    "  - Property names must exist in the log file's thermo output columns\n",
    "\n",
    "**Returns:** pandas DataFrame with 'step' column plus requested properties (only if available in log)\n",
    "\n",
    "**Example usage:**\n",
    "```python\n",
    "PROPERTIES_TO_PARSE = ['temp', 'press', 'pxx']  \n",
    "df = parse_thermo_log('simulation.log', PROPERTIES_TO_PARSE)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12773aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_thermo_log(log_file, properties) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parse LAMMPS log file and extract thermo data.\n",
    "    \n",
    "    Returns DataFrame with Step and requested properties that are available.\n",
    "    \"\"\"\n",
    "    data_rows = []\n",
    "    \n",
    "    try:\n",
    "        with open(log_file, 'r') as f:\n",
    "            content = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File {log_file} not found!\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    in_thermo_section = False\n",
    "    header_cols = []\n",
    "    \n",
    "    for line in content.split('\\n'):\n",
    "        line = line.strip()\n",
    "        \n",
    "        # Skip WARNING and ERROR lines but continue parsing\n",
    "        if line.startswith('WARNING') or line.startswith('ERROR'):\n",
    "            continue\n",
    "        \n",
    "        # Detect header line (contains Step and other properties)\n",
    "        if line.startswith('Step') or (in_thermo_section and 'Step' in line.split()):\n",
    "            header_cols = [col.lower() for col in line.split()]\n",
    "            in_thermo_section = True\n",
    "            continue\n",
    "        \n",
    "        # End of thermo section (only on Loop time, not warnings)\n",
    "        if in_thermo_section and 'Loop time' in line:\n",
    "            in_thermo_section = False\n",
    "            continue\n",
    "        \n",
    "        # Parse data line\n",
    "        if in_thermo_section and header_cols:\n",
    "            try:\n",
    "                values = line.split()\n",
    "                if len(values) >= len(header_cols):\n",
    "                    row_dict = {}\n",
    "                    for i, col in enumerate(header_cols):\n",
    "                        if col in ['step'] + [p.lower() for p in properties]:\n",
    "                            row_dict[col] = float(values[i])\n",
    "                    if row_dict:  # Only add if we got some data\n",
    "                        data_rows.append(row_dict)\n",
    "            except (ValueError, IndexError):\n",
    "                continue\n",
    "    \n",
    "    df = pd.DataFrame(data_rows)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d251ef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the log file to analyze\n",
    "CUSTOM_LOG_FILE = 'Eql.log'  # <-- Change this to your log file\n",
    "\n",
    "PROPERTIES = ['pxx', 'pyy', 'pzz']\n",
    "custom_df = parse_thermo_log(Path(CUSTOM_LOG_FILE), PROPERTIES)\n",
    "\n",
    "if custom_df.empty:\n",
    "    print(f\"⚠ Error: Could not parse {CUSTOM_LOG_FILE}\")\n",
    "else:\n",
    "    # Check which properties are available\n",
    "    available = [p for p in PROPERTIES if p in custom_df.columns]\n",
    "    missing = [p for p in PROPERTIES if p not in custom_df.columns]\n",
    "    \n",
    "    if missing:\n",
    "        print(f\"⚠ Missing properties (not in log): {missing}\")\n",
    "    \n",
    "    print(f\"✓ Loaded {len(custom_df)} data points\")\n",
    "    print(f\"✓ Available properties: {available}\")\n",
    "    print(f\"✓ Step range: {custom_df['step'].min():.0f} to {custom_df['step'].max():.0f}\")\n",
    "    # Mean of pxx and pyy columns step wise average store in P_Lateral\n",
    "    P_Lateral = (custom_df[\"pxx\"] + custom_df[\"pyy\"]) / 2\n",
    "    print(f'Average of lateral pressure components:{P_Lateral.mean()}')\n",
    "    print(f'Average of pzz pressure component:{custom_df[\"pzz\"].mean()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
